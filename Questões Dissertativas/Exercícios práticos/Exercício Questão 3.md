# Tratamento de Dados Ausentes em Machine Learning

Este reposit√≥rio apresenta um **exemplo pr√°tico de como lidar com dados ausentes (missing values)** em um conjunto de treinamento de *Machine Learning*, utilizando **Python**, **pandas** e **scikit-learn**, seguindo **boas pr√°ticas para evitar vazamento de dados (data leakage)**.

O cen√°rio utilizado √© uma **classifica√ß√£o de e-mails (spam / n√£o spam)** com vari√°veis num√©ricas que cont√™m valores ausentes.

---

## üìå Tecnologias Utilizadas

- Python 3.x  
- pandas  
- numpy  
- scikit-learn  

---

## üìÇ Estrutura do Exemplo

O fluxo do projeto segue as etapas cl√°ssicas de um pipeline de Machine Learning:

1. Cria√ß√£o do dataset com dados ausentes  
2. Separa√ß√£o entre vari√°veis de entrada e vari√°vel alvo  
3. Divis√£o em conjunto de treino e teste  
4. Tratamento de dados ausentes por imputa√ß√£o  
5. Treinamento do modelo  
6. Avalia√ß√£o do desempenho  
7. Uso de Pipeline como boa pr√°tica  

---

## 1Ô∏è‚É£ Criando um dataset de exemplo com dados ausentes

```python
import pandas as pd
import numpy as np

# Criando um dataset fict√≠cio
dados = {
    "num_palavras": [120, 300, np.nan, 250, 180, np.nan],
    "num_links": [2, np.nan, 1, 0, 3, 1],
    "spam": [0, 1, 0, 1, 0, 1]
}

df = pd.DataFrame(dados)
print(df)
```
---
## Exemplo de sa√≠da:

   num_palavras  num_links  spam
0         120.0        2.0     0
1         300.0        NaN     1
2           NaN        1.0     0
3         250.0        0.0     1
4         180.0        3.0     0
5           NaN        1.0     1

---

## 2Ô∏è‚É£ Separando vari√°veis de entrada e vari√°vel alvo:

```python
X = df.drop("spam", axis=1)
y = df["spam"]
```

---

## 3Ô∏è‚É£ Separando os conjuntos de treino e teste:

A separa√ß√£o correta evita vazamento de dados, garantindo uma avalia√ß√£o mais realista do modelo.

```python
from sklearn.model_selection import train_test_split

X_treino, X_teste, y_treino, y_teste = train_test_split(
    X, y, test_size=0.3, random_state=42
)
```

---

## 4Ô∏è‚É£ Tratamento de dados ausentes (Imputa√ß√£o):

Neste exemplo, utilizamos a mediana, que √© menos sens√≠vel a outliers e adequada para vari√°veis num√©ricas.

```python
from sklearn.impute import SimpleImputer

imputador = SimpleImputer(strategy="median")

# Ajuste apenas no conjunto de treino
X_treino_imputado = imputador.fit_transform(X_treino)

# Aplica√ß√£o no conjunto de teste
X_teste_imputado = imputador.transform(X_teste)
```

---

## 5Ô∏è‚É£ Treinamento do modelo:

Utilizamos Regress√£o Log√≠stica, um modelo cl√°ssico para problemas de classifica√ß√£o bin√°ria.

```python
from sklearn.linear_model import LogisticRegression

modelo = LogisticRegression()
modelo.fit(X_treino_imputado, y_treino)
```

---

## 6Ô∏è‚É£ Avalia√ß√£o do modelo:

```python
from sklearn.metrics import accuracy_score

y_pred = modelo.predict(X_teste_imputado)
acuracia = accuracy_score(y_teste, y_pred)

print(f"Acur√°cia do modelo: {acuracia:.2f}")
```

---

## 7Ô∏è‚É£ Boa pr√°tica: uso de Pipeline:

O uso de Pipeline organiza o fluxo de pr√©-processamento e treinamento, al√©m de reduzir o risco de erros e vazamento de dados.

```python
from sklearn.pipeline import Pipeline

pipeline = Pipeline([
    ("imputacao", SimpleImputer(strategy="median")),
    ("modelo", LogisticRegression())
])

pipeline.fit(X_treino, y_treino)
y_pred = pipeline.predict(X_teste)

print("Acur√°cia com Pipeline:", accuracy_score(y_teste, y_pred))
```

---

## üß† Principais Aprendizados:

- Dados ausentes s√£o comuns em datasets reais.
- A imputa√ß√£o deve ser ajustada somente com dados de treino.
- O 'SimpleImputer' facilita o tratamento de valores ausentes.
- 'Pipeline' √© uma boa pr√°tica essencial em projetos de Machine Learning.
- Um pr√©-processamento correto melhora a confiabilidade do modelo.

## üìé Conclus√£o

O tratamento adequado de dados ausentes √© uma etapa fundamental em projetos de Machine Learning.
Aplicar boas pr√°ticas, como imputa√ß√£o correta e uso de pipelines, contribui diretamente para modelos mais robustos, confi√°veis e com melhor capacidade de generaliza√ß√£o.
