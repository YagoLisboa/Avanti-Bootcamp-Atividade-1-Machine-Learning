# ğŸ Exemplo PrÃ¡tico em Python â€” Matriz de ConfusÃ£o

Neste exemplo, vamos utilizar Python para criar uma **matriz de confusÃ£o**
em um problema simples de **classificaÃ§Ã£o binÃ¡ria**, simulando a detecÃ§Ã£o de spam.

---

## ğŸ“¦ Bibliotecas utilizadas:

```python
from sklearn.metrics import confusion_matrix, classification_report
```
---

## ğŸ“Š Dados reais e previstos:

1 â†’ Spam
0 â†’ NÃ£o spam

```python
# Valores reais
y_true = [1, 0, 1, 1, 0, 0, 1, 0]

# Valores previstos pelo modelo
y_pred = [1, 0, 0, 1, 0, 1, 1, 0]
```
---

## ğŸ§® Criando a matriz de confusÃ£o:

```python
cm = confusion_matrix(y_true, y_pred)
print(cm)
```

## ğŸ” SaÃ­da esperada:

[[3 1]
 [1 3]]
 
---

## ğŸ“˜ InterpretaÃ§Ã£o da matriz
	
|            | Previsto 0 | Previsto 1 |
| ---------- | ---------- | ---------- |
| **Real 0** | 3 (VN)     | 1 (FP)     |
| **Real 1** | 1 (FN)     | 3 (VP)     |

- 3 Verdadeiros Negativos
- 3 Verdadeiros Positivos
- 1 Falso Positivo
- 1 Falso Negativo

---

## ğŸ“ˆ MÃ©tricas completas do modelo:

```python
print(classification_report(y_true, y_pred))
```

Exemplo de saÃ­da:

              precision    recall  f1-score   support

           0       0.75      0.75      0.75         4
           1       0.75      0.75      0.75         4

    accuracy                           0.75         8

---

## âœ… ConclusÃ£o

Este exemplo mostra como a matriz de confusÃ£o permite analisar o desempenho
de um modelo de classificaÃ§Ã£o de forma detalhada, indo alÃ©m da simples acurÃ¡cia
e revelando o tipo de erro cometido pelo modelo.
